<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python"/>
  <img src="https://img.shields.io/badge/Node.js-18+-339933?style=for-the-badge&logo=node.js&logoColor=white" alt="Node.js"/>
  <img src="https://img.shields.io/badge/Remotion-4.x-6C47FF?style=for-the-badge&logo=react&logoColor=white" alt="Remotion"/>
  <img src="https://img.shields.io/badge/FFmpeg-required-007808?style=for-the-badge&logo=ffmpeg&logoColor=white" alt="FFmpeg"/>
</p>

<h1 align="center">ğŸµ LyricFlow</h1>

<p align="center">
  <strong>One command. One MP3. One stunning lyric video.</strong>
</p>

<p align="center">
  <em>An AI-powered pipeline that transforms any Hindi song into a beautifully animated lyric video â€” fully automated, zero manual work.</em>
</p>

<br />

<p align="center">
  <img src="https://img.shields.io/badge/Vocal_Isolation-BS--Roformer-FF6B6B?style=flat-square" alt="BS-Roformer"/>
  <img src="https://img.shields.io/badge/Transcription-WhisperX_large--v3-4ECDC4?style=flat-square" alt="WhisperX"/>
  <img src="https://img.shields.io/badge/Refinement-Gemini_2.5_Pro-FFBE0B?style=flat-square" alt="Gemini"/>
  <img src="https://img.shields.io/badge/Video-Remotion-845EF7?style=flat-square" alt="Remotion"/>
</p>

---

## âœ¨ What It Does

Drop in an MP3 file, and LyricFlow handles **everything**:

```
ğŸ¤ MP3 File â”€â”€â”€â–º ğŸ”Š Vocal Isolation â”€â”€â”€â–º ğŸ“ Transcription â”€â”€â”€â–º ğŸ¤– AI Refinement â”€â”€â”€â–º ğŸ¬ Lyric Video
```

| Step | Engine | What Happens |
|:-----|:-------|:-------------|
| **1. Vocal Isolation** | BS-Roformer (Viper-2) | Separates vocals from instrumentals with LUFS normalization & high-pass filtering |
| **2. Transcription** | WhisperX `large-v3` | Word-level timestamps with forced alignment for precise sync |
| **3. AI Refinement** | Google Gemini 2.5 Pro | Corrects lyrics, transliterates Hindiâ†’Latin, groups into poetic lines |
| **4. Video Render** | Remotion (React) | Cinematic lyric video with animations, glow effects & progress bar |

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.10+**
- **Node.js 18+** & npm
- **FFmpeg** installed and available in PATH
- **Google Gemini API Key** ([Get one here](https://aistudio.google.com/apikey))

### 1ï¸âƒ£ Clone & Install Python Dependencies

```bash
git clone https://github.com/yourusername/lyricflow.git
cd lyricflow

pip install -r requirements.txt
```

### 2ï¸âƒ£ Install Video Dependencies

```bash
cd video
npm install
cd ..
```

### 3ï¸âƒ£ Set Up Environment

Create a `.env` file in the project root:

```env
GEMINI_API_KEY=your_gemini_api_key_here
```

### 4ï¸âƒ£ Run It! ğŸ‰

```bash
python main.py "path/to/your/song.mp3"
```

That's it. Your lyric video will be in `output_song/<song_name>/`.

---

## ğŸ“ Output Structure

```
output_song/
â””â”€â”€ your_song/
    â”œâ”€â”€ lyrics.json     # Timestamped, refined lyrics
    â””â”€â”€ your_song.mp4   # The final lyric video (1920Ã—1080)
```

<details>
<summary><b>ğŸ“‹ Example <code>lyrics.json</code></b></summary>

```json
[
  {
    "text": "Subah ki dhoop si naya hai yeh savera",
    "start": 28.84,
    "end": 33.66
  },
  {
    "text": "Peeche chhoot gaya woh raat ka andhera",
    "start": 33.9,
    "end": 38.63
  },
  {
    "text": "Chalo chalein khwabon ke shehar",
    "start": 59.43,
    "end": 62.26
  }
]
```

</details>

---

## ğŸ—ï¸ Architecture

```mermaid
graph LR
    A["ğŸµ MP3 Input"] --> B["ğŸ”Š audio_utils.py"]
    B -->|"LUFS Norm + BS-Roformer + HPF"| C["ğŸ¤ Clean Vocals"]
    C --> D["ğŸ“ transcribe_engine.py"]
    D -->|"WhisperX large-v3 + Alignment"| E["ğŸ“Š Word-Level Timestamps"]
    E --> F["ğŸ¤– text_refinery.py"]
    F -->|"Gemini 2.5 Pro"| G["âœ… lyrics.json"]
    G --> H["ğŸ¬ Remotion Video"]
    A --> H
    H --> I["ğŸ¥ Final MP4"]

    style A fill:#FF6B6B,stroke:#333,color:#fff
    style C fill:#4ECDC4,stroke:#333,color:#fff
    style E fill:#45B7D1,stroke:#333,color:#fff
    style G fill:#FFBE0B,stroke:#333,color:#000
    style I fill:#845EF7,stroke:#333,color:#fff
```

---

## ğŸ“‚ Project Structure

```
lyricflow/
â”œâ”€â”€ main.py                  # ğŸ¯ Orchestrator â€” runs the full pipeline
â”œâ”€â”€ audio_utils.py           # ğŸ”Š Vocal isolation (BS-Roformer + FFmpeg)
â”œâ”€â”€ transcribe_engine.py     # ğŸ“ WhisperX transcription & alignment
â”œâ”€â”€ text_refinery.py         # ğŸ¤– Gemini lyric refinement
â”œâ”€â”€ requirements.txt         # ğŸ“¦ Python dependencies
â”œâ”€â”€ .env                     # ğŸ”‘ API keys (not committed)
â”‚
â”œâ”€â”€ video/                   # ğŸ¬ Remotion video project
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ Root.tsx         #    Remotion composition setup
â”‚   â”‚   â””â”€â”€ index.ts         #    Entry point
â”‚   â”œâ”€â”€ public/              #    Auto-populated audio & lyrics
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tsconfig.json
â”‚
â”œâ”€â”€ output_song/             # ğŸ“ Generated outputs per song
â”œâ”€â”€ separated/               # ğŸ¤ Intermediate vocal files
â””â”€â”€ models/                  # ğŸ§  Cached AI models
```

---

## âš™ï¸ Advanced Usage

### Custom API Key (without `.env`)

```bash
python main.py "song.mp3" --api-key YOUR_API_KEY
```

### Preview Video in Browser

```bash
cd video
npm start
```

Opens the Remotion Studio at `localhost:3000` for real-time preview.

### Render Video Separately

```bash
cd video
npm run render
```

---

## ğŸ§  How Each Module Works

<details>
<summary><b>ğŸ”Š Vocal Isolation â€” <code>audio_utils.py</code></b></summary>

<br />

Uses a 3-stage audio processing pipeline:

1. **LUFS Normalization** â€” Normalizes input to âˆ’14 LUFS for consistent volume
2. **BS-Roformer Separation** â€” State-of-the-art model (`model_bs_roformer_ep_317_sdr_12.9755`) isolates vocals from instrumentals
3. **100Hz High-Pass Filter** â€” Removes sub-bass rumble that confuses transcription models

The model is automatically downloaded from Hugging Face on first run.

</details>

<details>
<summary><b>ğŸ“ Transcription â€” <code>transcribe_engine.py</code></b></summary>

<br />

- Loads the **WhisperX `large-v3`** model for Hindi (`hi`) transcription
- Performs **forced alignment** to get word-level timestamps (not just segment-level)
- Outputs precise `start`/`end` times rounded to 2 decimal places for every word
- Runs on CPU by default for maximum compatibility (GPU supported)

</details>

<details>
<summary><b>ğŸ¤– AI Refinement â€” <code>text_refinery.py</code></b></summary>

<br />

Sends word-level timestamps to **Gemini 2.5 Pro** with instructions to:

- âœ… Group words into natural, poetic lyric lines (6â€“10 words each)
- âœ… Correct Hindi spelling errors from ASR output
- âœ… Transliterate to Latin script (Hindi â†’ Roman phonetics)
- âœ… Preserve exact timestamps â€” no interpolation or guessing

Falls back to raw transcription if AI refinement fails.

</details>

<details>
<summary><b>ğŸ¬ Video Rendering â€” <code>video/</code></b></summary>

<br />

Built with **Remotion** (React-based programmatic video):

- ğŸ¨ Cinematic dark gradient background with animated glow
- âœ¨ Fade-in/out lyric animations with smooth slide transitions
- ğŸ“Š Animated progress bar with gradient styling
- ğŸµ Synchronized audio playback
- ğŸ“ Full HD output (1920Ã—1080 @ 30fps)

</details>

---

## ğŸ“‹ Requirements

| Dependency | Purpose |
|:-----------|:--------|
| `audio-separator` | BS-Roformer vocal isolation |
| `whisperx` | Speech-to-text with forced alignment |
| `google-generativeai` | Gemini 2.5 Pro lyric refinement |
| `torch` / `torchaudio` | PyTorch backend for ML models |
| `remotion` | Programmatic video rendering |
| `ffmpeg` | Audio pre/post-processing |

---

## ğŸ¤” FAQ

<details>
<summary><b>Does it work on non-Hindi songs?</b></summary>

The pipeline is optimized for Hindi, but you can modify the `language` parameter in `transcribe_engine.py` and adjust the Gemini prompt in `text_refinery.py` to support other languages.

</details>

<details>
<summary><b>Do I need a GPU?</b></summary>

No! The pipeline runs on CPU by default. A GPU will speed up transcription significantly, but it's not required.

</details>

<details>
<summary><b>How long does it take?</b></summary>

A typical 3-4 minute song takes ~5-10 minutes on CPU (vocal isolation + transcription + rendering). With a GPU, this drops to ~2-3 minutes.

</details>

<details>
<summary><b>Is the Gemini API free?</b></summary>

Google offers a free tier for Gemini API. A single song refinement uses minimal tokens, so the free tier should be more than sufficient for personal use.

</details>

---

## ğŸ“œ License

This project is open source and available under the [MIT License](LICENSE).

---

<p align="center">
  <strong>Made with â¤ï¸ and way too much caffeine</strong>
  <br />
  <sub>If this helped you, consider giving it a â­</sub>
</p>
